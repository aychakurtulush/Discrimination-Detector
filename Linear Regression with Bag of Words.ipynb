{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3430cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36678287",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>disc_cat</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>disc_cat_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587451436683264</td>\n",
       "      <td>bitch lmfaooooo gone rock sock ass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587450710958081</td>\n",
       "      <td>nvr vw person simpli cost repair hassl get don...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587450673319940</td>\n",
       "      <td>hate wen bitch say stop act care df said act l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587450547634179</td>\n",
       "      <td>dnc pay well ask brooklyn dad hes lucki get pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587449503264769</td>\n",
       "      <td>sinong bitch ba yung hindi marunong mag sorri ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187658489856</td>\n",
       "      <td>happi st david day everyon wale council blind ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187603959808</td>\n",
       "      <td>congrat sir pls sir want sir better nigeria pu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187595472896</td>\n",
       "      <td>ne abbiamo sempr bisogno</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187587100672</td>\n",
       "      <td>wait video channel bro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187578712064</td>\n",
       "      <td>nhn cartier vng chim ngng v khng th chi nhn ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310919 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date                   id  \\\n",
       "0       28 February 2023  1630587451436683264   \n",
       "1       28 February 2023  1630587450710958081   \n",
       "2       28 February 2023  1630587450673319940   \n",
       "3       28 February 2023  1630587450547634179   \n",
       "4       28 February 2023  1630587449503264769   \n",
       "...                  ...                  ...   \n",
       "99996      01 March 2023  1630854187658489856   \n",
       "99997      01 March 2023  1630854187603959808   \n",
       "99998      01 March 2023  1630854187595472896   \n",
       "99999      01 March 2023  1630854187587100672   \n",
       "100000     01 March 2023  1630854187578712064   \n",
       "\n",
       "                                                  content  likes  retweets  \\\n",
       "0                      bitch lmfaooooo gone rock sock ass      0         0   \n",
       "1       nvr vw person simpli cost repair hassl get don...      0         0   \n",
       "2       hate wen bitch say stop act care df said act l...      0         0   \n",
       "3       dnc pay well ask brooklyn dad hes lucki get pe...      0         0   \n",
       "4       sinong bitch ba yung hindi marunong mag sorri ...      0         0   \n",
       "...                                                   ...    ...       ...   \n",
       "99996   happi st david day everyon wale council blind ...      0         0   \n",
       "99997   congrat sir pls sir want sir better nigeria pu...      0         0   \n",
       "99998                            ne abbiamo sempr bisogno      0         0   \n",
       "99999                              wait video channel bro      0         0   \n",
       "100000  nhn cartier vng chim ngng v khng th chi nhn ca...      0         0   \n",
       "\n",
       "       disc_cat  Unnamed: 0.1  disc_cat_num  \n",
       "0        gender           NaN             2  \n",
       "1        gender           NaN             2  \n",
       "2        gender           NaN             2  \n",
       "3        gender           NaN             2  \n",
       "4        gender           NaN             2  \n",
       "...         ...           ...           ...  \n",
       "99996   control           NaN             0  \n",
       "99997   control           NaN             0  \n",
       "99998   control           NaN             0  \n",
       "99999   control           NaN             0  \n",
       "100000  control           NaN             0  \n",
       "\n",
       "[310919 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "tweets_d = pd.read_csv('Data/tweets_disc_cleaned.csv')\n",
    "tweets_c = pd.read_csv('Data/tweets_ctrl_cleaned.csv')\n",
    "data = pd.concat([tweets_d, tweets_c])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a5926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaN values\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dcb8dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>disc_cat</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>disc_cat_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105210</th>\n",
       "      <td>02 March 2023</td>\n",
       "      <td>1631255697756405762</td>\n",
       "      <td>sam v wish new littl gf rot depht karma cuz bi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105211</th>\n",
       "      <td>02 March 2023</td>\n",
       "      <td>1631255696724336640</td>\n",
       "      <td>ye bharwi yehi kuch kr sakti hein dakait terro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105212</th>\n",
       "      <td>02 March 2023</td>\n",
       "      <td>1631255695059472385</td>\n",
       "      <td>thought pattern becom much much wider ca cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105213</th>\n",
       "      <td>02 March 2023</td>\n",
       "      <td>1631255691955511297</td>\n",
       "      <td>sound bitch</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105214</th>\n",
       "      <td>02 March 2023</td>\n",
       "      <td>1631255691724816385</td>\n",
       "      <td>bitchsham candac mayb enough peopl shame canda...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210912</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630401486483251203</td>\n",
       "      <td>state lost confederaci</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mental_health</td>\n",
       "      <td>105705.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210914</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630401254798118913</td>\n",
       "      <td>make sens</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mental_health</td>\n",
       "      <td>105707.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210915</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630401175995527169</td>\n",
       "      <td>mean make sens miz host</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mental_health</td>\n",
       "      <td>105708.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210916</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630400994222948352</td>\n",
       "      <td>disrespect key lime pieoh use lubric</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mental_health</td>\n",
       "      <td>105709.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210917</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630400083152994304</td>\n",
       "      <td>compartment nois block itkeep</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mental_health</td>\n",
       "      <td>105710.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94520 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date                   id  \\\n",
       "105210     02 March 2023  1631255697756405762   \n",
       "105211     02 March 2023  1631255696724336640   \n",
       "105212     02 March 2023  1631255695059472385   \n",
       "105213     02 March 2023  1631255691955511297   \n",
       "105214     02 March 2023  1631255691724816385   \n",
       "...                  ...                  ...   \n",
       "210912  28 February 2023  1630401486483251203   \n",
       "210914  28 February 2023  1630401254798118913   \n",
       "210915  28 February 2023  1630401175995527169   \n",
       "210916  28 February 2023  1630400994222948352   \n",
       "210917  28 February 2023  1630400083152994304   \n",
       "\n",
       "                                                  content  likes  retweets  \\\n",
       "105210  sam v wish new littl gf rot depht karma cuz bi...      0         0   \n",
       "105211  ye bharwi yehi kuch kr sakti hein dakait terro...      0         0   \n",
       "105212    thought pattern becom much much wider ca cancer      0         0   \n",
       "105213                                        sound bitch      0         0   \n",
       "105214  bitchsham candac mayb enough peopl shame canda...      0         0   \n",
       "...                                                   ...    ...       ...   \n",
       "210912                             state lost confederaci      0         0   \n",
       "210914                                          make sens      1         0   \n",
       "210915                            mean make sens miz host      0         0   \n",
       "210916               disrespect key lime pieoh use lubric      1         0   \n",
       "210917                      compartment nois block itkeep      0         0   \n",
       "\n",
       "             disc_cat  Unnamed: 0.1  disc_cat_num  \n",
       "105210         gender           0.0             2  \n",
       "105211         gender           1.0             2  \n",
       "105212         gender           2.0             2  \n",
       "105213         gender           3.0             2  \n",
       "105214         gender           4.0             2  \n",
       "...               ...           ...           ...  \n",
       "210912  mental_health      105705.0             4  \n",
       "210914  mental_health      105707.0             4  \n",
       "210915  mental_health      105708.0             4  \n",
       "210916  mental_health      105709.0             4  \n",
       "210917  mental_health      105710.0             4  \n",
       "\n",
       "[94520 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4319f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bag of words representation of the tweets\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(data['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a67a4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>health</th>\n",
       "      <th>mental_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bitch</td>\n",
       "      <td>fag</td>\n",
       "      <td>n-word</td>\n",
       "      <td>crazy</td>\n",
       "      <td>crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whore</td>\n",
       "      <td>dyke</td>\n",
       "      <td>nigga</td>\n",
       "      <td>lunatic</td>\n",
       "      <td>lunatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slut</td>\n",
       "      <td>tranny</td>\n",
       "      <td>nigger</td>\n",
       "      <td>psycho</td>\n",
       "      <td>psycho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cunt</td>\n",
       "      <td>shemale</td>\n",
       "      <td>spic</td>\n",
       "      <td>nutjob</td>\n",
       "      <td>nutjob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ho</td>\n",
       "      <td>chick with a dick</td>\n",
       "      <td>chink</td>\n",
       "      <td>schizo</td>\n",
       "      <td>schizo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>manspread</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>bro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>dude</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>guy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sex             gender    race   health mental_health\n",
       "0       bitch                fag  n-word    crazy         crazy\n",
       "1       whore               dyke   nigga  lunatic       lunatic\n",
       "2        slut             tranny  nigger   psycho        psycho\n",
       "3        cunt            shemale    spic   nutjob        nutjob\n",
       "4          ho  chick with a dick   chink   schizo        schizo\n",
       "..        ...                ...     ...      ...           ...\n",
       "68  manspread                NaN     NaN      NaN           NaN\n",
       "69        bro                NaN     NaN      NaN           NaN\n",
       "70       dude                NaN     NaN      NaN           NaN\n",
       "71        guy                NaN     NaN      NaN           NaN\n",
       "72        man                NaN     NaN      NaN           NaN\n",
       "\n",
       "[73 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminatory_words_pd= pd.read_csv('Data/discriminatory_words.csv')\n",
    "discriminatory_words_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a1d405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex              object\n",
       "gender           object\n",
       "race             object\n",
       "health           object\n",
       "mental_health    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminatory_words_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80682736",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminatory_words_pd = discriminatory_words_pd.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463848a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminatory_words = {'sex': discriminatory_words_pd['sex'], 'gender' : discriminatory_words_pd['gender'], 'race' : discriminatory_words_pd['race'], 'health' : discriminatory_words_pd['health'], 'mental_health' : discriminatory_words_pd['mental_health']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c99d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Add features for the presence of each discriminatory word\n",
    "for category, words in discriminatory_words_pd.items():\n",
    "    category_cols = [vectorizer.vocabulary_.get(word) for word in words]\n",
    "    category_cols = [col for col in category_cols if col is not None and col in data.columns]\n",
    "    if len(category_cols) > 0:\n",
    "        word_col = data[category_cols].sum(axis=1)\n",
    "        X = hstack([X, csr_matrix(word_col.values.reshape(-1, 1))])\n",
    "    else:\n",
    "        X = hstack([X, csr_matrix(np.zeros((data.shape[0], 1)))])\n",
    "        \n",
    "X = X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca0e07e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105210</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105211</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105212</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105213</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105214</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210912</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210914</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210915</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210916</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210917</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94520 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [105210, 105211, 105212, 105213, 105214, 105215, 105216, 105217, 105218, 105219, 105220, 105221, 105222, 105223, 105224, 105225, 105226, 105227, 105228, 105229, 105230, 105231, 105232, 105234, 105235, 105236, 105237, 105238, 105239, 105241, 105242, 105243, 105244, 105245, 105246, 105247, 105248, 105249, 105250, 105251, 105252, 105253, 105254, 105255, 105256, 105257, 105258, 105259, 105260, 105262, 105263, 105264, 105265, 105266, 105268, 105269, 105270, 105271, 105274, 105275, 105276, 105277, 105278, 105279, 105281, 105282, 105283, 105284, 105285, 105286, 105287, 105288, 105289, 105290, 105291, 105292, 105293, 105294, 105295, 105296, 105297, 105298, 105299, 105300, 105301, 105302, 105303, 105304, 105305, 105307, 105308, 105309, 105310, 105311, 105312, 105313, 105314, 105315, 105316, 105317, ...]\n",
       "\n",
       "[94520 rows x 0 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[category_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ead80ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23140\\3718106941.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdiscriminatory_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mnum_discriminatory_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Add the new column to the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23140\\3718106941.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdiscriminatory_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mnum_discriminatory_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Add the new column to the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    958\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    961\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   3620\u001b[0m             \u001b[1;31m#  results if our categories are integers that dont match our codes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3621\u001b[0m             \u001b[1;31m# IntervalIndex: IntervalTree has no get_loc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3622\u001b[1;33m             \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3623\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Convert all values in discriminatory_words to strings\n",
    "for category, words in discriminatory_words.items():\n",
    "    discriminatory_words[category] = [str(word) for word in words]\n",
    "\n",
    "# Compute the number of discriminatory words in each tweet\n",
    "num_discriminatory_words = []\n",
    "num_discriminatory_words = [sum(data['content'].str.contains(word) for word in words) for category, words in discriminatory_words.items() for i in range(len(data))]\n",
    "\n",
    "# Add the new column to the dataframe\n",
    "data['num_discriminatory_words'] = num_discriminatory_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the number of discriminatory words as the label\n",
    "y = data['num_discriminatory_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78742d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6909d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean squared error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bcb4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide suggestions based on the number of discriminatory words\n",
    "if y_pred < 2:\n",
    "    print('This tweet contains no discriminatory language.')\n",
    "elif y_pred < 5:\n",
    "    print('Consider revising this tweet to remove any potentially discriminatory language.')\n",
    "else:\n",
    "    print('This tweet contains a high number of discriminatory words and should be reviewed carefully.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
