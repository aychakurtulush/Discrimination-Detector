{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c9dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import re\n",
    "import emoji\n",
    "from datetime import datetime\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae61044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kurtu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kurtu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kurtu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\kurtu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install emoji\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f278bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>disc_cat</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-28 15:15:17+00:00</td>\n",
       "      <td>1630587451436683264</td>\n",
       "      <td>@BuckTheBoss_ Bitch LMFAOOOOO gone rock the so...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-28 15:15:17+00:00</td>\n",
       "      <td>1630587450710958081</td>\n",
       "      <td>@davenewworld_2 Im a nvr VW person simply bc t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-28 15:15:17+00:00</td>\n",
       "      <td>1630587450673319940</td>\n",
       "      <td>I hate wen a bitch say ‚Äústop acting like u don...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-28 15:15:17+00:00</td>\n",
       "      <td>1630587450547634179</td>\n",
       "      <td>@JJohnson2460 @Todd66251244 @JoJoFromJerz DNC ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-28 15:15:17+00:00</td>\n",
       "      <td>1630587449503264769</td>\n",
       "      <td>Sinong bitch ba yung hindi marunong mag sorry ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>2023-03-01 08:55:12+00:00</td>\n",
       "      <td>1630854187658489856</td>\n",
       "      <td>üè¥Û†ÅßÛ†Å¢Û†Å∑Û†Å¨Û†Å≥Û†ÅøA very Happy St David's Day from everyo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2023-03-01 08:55:12+00:00</td>\n",
       "      <td>1630854187603959808</td>\n",
       "      <td>@ARISEtv Congrats sir pls sir what I want for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2023-03-01 08:55:12+00:00</td>\n",
       "      <td>1630854187595472896</td>\n",
       "      <td>@the_head_ofA ne abbiamo sempre bisogno</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>2023-03-01 08:55:12+00:00</td>\n",
       "      <td>1630854187587100672</td>\n",
       "      <td>@JaqubAjmal Wait, what!\\n\\nVideo on the channe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>2023-03-01 08:55:12+00:00</td>\n",
       "      <td>1630854187578712064</td>\n",
       "      <td>Nh·∫´n Cartier 3 v√≤ng: Chi√™m ng∆∞·ª°ng v·∫ª ƒë·∫πp \"kh√¥n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310919 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date                   id  \\\n",
       "0       2023-02-28 15:15:17+00:00  1630587451436683264   \n",
       "1       2023-02-28 15:15:17+00:00  1630587450710958081   \n",
       "2       2023-02-28 15:15:17+00:00  1630587450673319940   \n",
       "3       2023-02-28 15:15:17+00:00  1630587450547634179   \n",
       "4       2023-02-28 15:15:17+00:00  1630587449503264769   \n",
       "...                           ...                  ...   \n",
       "99996   2023-03-01 08:55:12+00:00  1630854187658489856   \n",
       "99997   2023-03-01 08:55:12+00:00  1630854187603959808   \n",
       "99998   2023-03-01 08:55:12+00:00  1630854187595472896   \n",
       "99999   2023-03-01 08:55:12+00:00  1630854187587100672   \n",
       "100000  2023-03-01 08:55:12+00:00  1630854187578712064   \n",
       "\n",
       "                                                  content  likes  retweets  \\\n",
       "0       @BuckTheBoss_ Bitch LMFAOOOOO gone rock the so...      0         0   \n",
       "1       @davenewworld_2 Im a nvr VW person simply bc t...      0         0   \n",
       "2       I hate wen a bitch say ‚Äústop acting like u don...      0         0   \n",
       "3       @JJohnson2460 @Todd66251244 @JoJoFromJerz DNC ...      0         0   \n",
       "4       Sinong bitch ba yung hindi marunong mag sorry ...      0         0   \n",
       "...                                                   ...    ...       ...   \n",
       "99996   üè¥Û†ÅßÛ†Å¢Û†Å∑Û†Å¨Û†Å≥Û†ÅøA very Happy St David's Day from everyo...      0         0   \n",
       "99997   @ARISEtv Congrats sir pls sir what I want for ...      0         0   \n",
       "99998             @the_head_ofA ne abbiamo sempre bisogno      0         0   \n",
       "99999   @JaqubAjmal Wait, what!\\n\\nVideo on the channe...      0         0   \n",
       "100000  Nh·∫´n Cartier 3 v√≤ng: Chi√™m ng∆∞·ª°ng v·∫ª ƒë·∫πp \"kh√¥n...      0         0   \n",
       "\n",
       "       disc_cat  Unnamed: 0.1  \n",
       "0        gender           NaN  \n",
       "1        gender           NaN  \n",
       "2        gender           NaN  \n",
       "3        gender           NaN  \n",
       "4        gender           NaN  \n",
       "...         ...           ...  \n",
       "99996   control           NaN  \n",
       "99997   control           NaN  \n",
       "99998   control           NaN  \n",
       "99999   control           NaN  \n",
       "100000  control           NaN  \n",
       "\n",
       "[310919 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_d = pd.read_csv(\"Data/tweet_no_duplicates.csv\")\n",
    "tweets_d2 = pd.read_csv(\"Data/secondround_tweet_no_duplicates.csv\")\n",
    "tweets_c = pd.read_csv(\"Data/tweet_control.csv\")\n",
    "tweets = pd.concat([tweets_d, tweets_d2, tweets_c])\n",
    "tweets = tweets.drop(columns=['Unnamed: 0'], axis=1)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a197c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date             object\n",
      "id                int64\n",
      "content          object\n",
      "likes             int64\n",
      "retweets          int64\n",
      "disc_cat         object\n",
      "Unnamed: 0.1    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(tweets.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f533dd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['content'] = tweets['content'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30a149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regular expressions for hashtags and mentions\n",
    "hashtag_pattern = re.compile(r'#\\w+')\n",
    "mention_pattern = re.compile(r'@\\w+')\n",
    "url_pattern = re.compile(r'https?://\\S+')\n",
    "non_text_pattern = re.compile(r'[^a-zA-Z\\s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4363839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove emojis from a string using regular expressions\n",
    "def remove_emojis(tweets):\n",
    "    # Define regular expression pattern for emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    # Remove emojis from the string\n",
    "    return emoji_pattern.sub(r'', tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e27c57ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the text content of a tweet and remove hashtags, mentions, URLs, emojis and non-text characters, also convert to lowercase\n",
    "def clean_tweets(tweets):\n",
    "    tweets = hashtag_pattern.sub('', tweets)\n",
    "    tweets = mention_pattern.sub('', tweets)\n",
    "    tweets = url_pattern.sub('', tweets)\n",
    "    tweets = remove_emojis(tweets)\n",
    "    tweets = non_text_pattern.sub('', tweets)\n",
    "    tweets = tweets.lower()\n",
    "    return tweets\n",
    "\n",
    "# Apply the clean_tweet function to the 'content' column of the DataFrame\n",
    "tweets['content'] = tweets['content'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "890cfbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>disc_cat</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-28 15:15:17+00:00</td>\n",
       "      <td>1630587451436683264</td>\n",
       "      <td>bitch lmfaooooo gone rock the socks off yo ass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-28 15:15:17+00:00</td>\n",
       "      <td>1630587450710958081</td>\n",
       "      <td>im a nvr vw person simply bc the cost of repa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-28 15:15:17+00:00</td>\n",
       "      <td>1630587450673319940</td>\n",
       "      <td>i hate wen a bitch say stop acting like u dont...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-28 15:15:17+00:00</td>\n",
       "      <td>1630587450547634179</td>\n",
       "      <td>dnc pays me well  ask brooklyn dad about it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-28 15:15:17+00:00</td>\n",
       "      <td>1630587449503264769</td>\n",
       "      <td>sinong bitch ba yung hindi marunong mag sorry ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>2023-03-01 08:55:12+00:00</td>\n",
       "      <td>1630854187658489856</td>\n",
       "      <td>a very happy st davids day from everyone at wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2023-03-01 08:55:12+00:00</td>\n",
       "      <td>1630854187603959808</td>\n",
       "      <td>congrats sir pls sir what i want for u sir is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2023-03-01 08:55:12+00:00</td>\n",
       "      <td>1630854187595472896</td>\n",
       "      <td>ne abbiamo sempre bisogno</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>2023-03-01 08:55:12+00:00</td>\n",
       "      <td>1630854187587100672</td>\n",
       "      <td>wait what\\n\\nvideo on the channel bro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>2023-03-01 08:55:12+00:00</td>\n",
       "      <td>1630854187578712064</td>\n",
       "      <td>nhn cartier  vng chim ngng v p khng th chi t  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310919 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date                   id  \\\n",
       "0       2023-02-28 15:15:17+00:00  1630587451436683264   \n",
       "1       2023-02-28 15:15:17+00:00  1630587450710958081   \n",
       "2       2023-02-28 15:15:17+00:00  1630587450673319940   \n",
       "3       2023-02-28 15:15:17+00:00  1630587450547634179   \n",
       "4       2023-02-28 15:15:17+00:00  1630587449503264769   \n",
       "...                           ...                  ...   \n",
       "99996   2023-03-01 08:55:12+00:00  1630854187658489856   \n",
       "99997   2023-03-01 08:55:12+00:00  1630854187603959808   \n",
       "99998   2023-03-01 08:55:12+00:00  1630854187595472896   \n",
       "99999   2023-03-01 08:55:12+00:00  1630854187587100672   \n",
       "100000  2023-03-01 08:55:12+00:00  1630854187578712064   \n",
       "\n",
       "                                                  content  likes  retweets  \\\n",
       "0          bitch lmfaooooo gone rock the socks off yo ass      0         0   \n",
       "1        im a nvr vw person simply bc the cost of repa...      0         0   \n",
       "2       i hate wen a bitch say stop acting like u dont...      0         0   \n",
       "3          dnc pays me well  ask brooklyn dad about it...      0         0   \n",
       "4       sinong bitch ba yung hindi marunong mag sorry ...      0         0   \n",
       "...                                                   ...    ...       ...   \n",
       "99996   a very happy st davids day from everyone at wa...      0         0   \n",
       "99997    congrats sir pls sir what i want for u sir is...      0         0   \n",
       "99998                           ne abbiamo sempre bisogno      0         0   \n",
       "99999              wait what\\n\\nvideo on the channel bro       0         0   \n",
       "100000  nhn cartier  vng chim ngng v p khng th chi t  ...      0         0   \n",
       "\n",
       "       disc_cat  Unnamed: 0.1  \n",
       "0        gender           NaN  \n",
       "1        gender           NaN  \n",
       "2        gender           NaN  \n",
       "3        gender           NaN  \n",
       "4        gender           NaN  \n",
       "...         ...           ...  \n",
       "99996   control           NaN  \n",
       "99997   control           NaN  \n",
       "99998   control           NaN  \n",
       "99999   control           NaN  \n",
       "100000  control           NaN  \n",
       "\n",
       "[310919 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68709745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the date format\n",
    "def clean_date(date_str):\n",
    "    # Convert string to datetime object\n",
    "    date_obj = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S+00:00')\n",
    "    # Format datetime object as string in 'day month year' format\n",
    "    date_str = date_obj.strftime('%d %B %Y')\n",
    "    return date_str\n",
    "\n",
    "# Apply the clean_date function to the 'date' column of the DataFrame\n",
    "tweets['date'] = tweets['date'].apply(clean_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "378d5b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>disc_cat</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587451436683264</td>\n",
       "      <td>bitch lmfaooooo gone rock the socks off yo ass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587450710958081</td>\n",
       "      <td>im a nvr vw person simply bc the cost of repa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587450673319940</td>\n",
       "      <td>i hate wen a bitch say stop acting like u dont...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587450547634179</td>\n",
       "      <td>dnc pays me well  ask brooklyn dad about it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587449503264769</td>\n",
       "      <td>sinong bitch ba yung hindi marunong mag sorry ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187658489856</td>\n",
       "      <td>a very happy st davids day from everyone at wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187603959808</td>\n",
       "      <td>congrats sir pls sir what i want for u sir is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187595472896</td>\n",
       "      <td>ne abbiamo sempre bisogno</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187587100672</td>\n",
       "      <td>wait what\\n\\nvideo on the channel bro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187578712064</td>\n",
       "      <td>nhn cartier  vng chim ngng v p khng th chi t  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310919 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date                   id  \\\n",
       "0       28 February 2023  1630587451436683264   \n",
       "1       28 February 2023  1630587450710958081   \n",
       "2       28 February 2023  1630587450673319940   \n",
       "3       28 February 2023  1630587450547634179   \n",
       "4       28 February 2023  1630587449503264769   \n",
       "...                  ...                  ...   \n",
       "99996      01 March 2023  1630854187658489856   \n",
       "99997      01 March 2023  1630854187603959808   \n",
       "99998      01 March 2023  1630854187595472896   \n",
       "99999      01 March 2023  1630854187587100672   \n",
       "100000     01 March 2023  1630854187578712064   \n",
       "\n",
       "                                                  content  likes  retweets  \\\n",
       "0          bitch lmfaooooo gone rock the socks off yo ass      0         0   \n",
       "1        im a nvr vw person simply bc the cost of repa...      0         0   \n",
       "2       i hate wen a bitch say stop acting like u dont...      0         0   \n",
       "3          dnc pays me well  ask brooklyn dad about it...      0         0   \n",
       "4       sinong bitch ba yung hindi marunong mag sorry ...      0         0   \n",
       "...                                                   ...    ...       ...   \n",
       "99996   a very happy st davids day from everyone at wa...      0         0   \n",
       "99997    congrats sir pls sir what i want for u sir is...      0         0   \n",
       "99998                           ne abbiamo sempre bisogno      0         0   \n",
       "99999              wait what\\n\\nvideo on the channel bro       0         0   \n",
       "100000  nhn cartier  vng chim ngng v p khng th chi t  ...      0         0   \n",
       "\n",
       "       disc_cat  Unnamed: 0.1  \n",
       "0        gender           NaN  \n",
       "1        gender           NaN  \n",
       "2        gender           NaN  \n",
       "3        gender           NaN  \n",
       "4        gender           NaN  \n",
       "...         ...           ...  \n",
       "99996   control           NaN  \n",
       "99997   control           NaN  \n",
       "99998   control           NaN  \n",
       "99999   control           NaN  \n",
       "100000  control           NaN  \n",
       "\n",
       "[310919 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50d365bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kurtu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kurtu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'rt',\n",
       " 'mkr',\n",
       " 'didn',\n",
       " 'bc',\n",
       " 'n',\n",
       " 'm',\n",
       " 'im',\n",
       " 'll',\n",
       " 'y',\n",
       " 've',\n",
       " 'u',\n",
       " 'ur',\n",
       " 'don',\n",
       " 'p',\n",
       " 't',\n",
       " 's',\n",
       " 'aren',\n",
       " 'kp',\n",
       " 'o',\n",
       " 'kat',\n",
       " 'de',\n",
       " 're',\n",
       " 'amp',\n",
       " 'will',\n",
       " 'wa',\n",
       " 'w',\n",
       " 'e',\n",
       " 'vc',\n",
       " 'like',\n",
       " 'yo',\n",
       " 'bc',\n",
       " 'amp',\n",
       " 'nan']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "extras = ['rt', 'mkr', 'didn', 'bc', 'n', 'm', 'im', 'll', 'y', 've', 'u', 'ur', \n",
    "          'don', 'p', 't', 's', 'aren', 'kp', 'o', 'kat', 'de', 're', 'amp', 'will', \n",
    "          'wa', 'w', 'e', 'vc', 'like', 'yo', 'bc', 'amp', 'nan']\n",
    "stop_words.extend(extras)\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e378b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b45319b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['content'] = tweets['content'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d41b6c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\n",
    "    \"ain't\": \"is not\",\n",
    "    \"r\": \"are\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"cant\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"didnt\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"dont\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"kno\" : \"know\", \n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldv\" : \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8560a87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\kurtu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('omw-1.4')\n",
    "lem = WordNetLemmatizer()\n",
    "stemmer=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d78fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    #removing hastags and links\n",
    "    text=\" \".join(text.split())\n",
    "    \n",
    "    #stemming\n",
    "    text=\" \".join([stemmer.stem(word) for word in text.split()])\n",
    "    \n",
    "    #remove shortands\n",
    "    s=''\n",
    "    for word in text.split():\n",
    "        if word in CONTRACTION_MAP.keys():\n",
    "            s=s+' '+CONTRACTION_MAP[word];\n",
    "        else:\n",
    "            s=s+' '+word\n",
    "    text=s\n",
    "    \n",
    "    #remove puncutations\n",
    "    punc=re.compile(r\"[^\\w\\s]\")\n",
    "    text=punc.sub('',text)\n",
    "    \n",
    "    #remove stop words\n",
    "    text=\" \".join(word for word in text.split() if word not in stop_words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ddde0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['content']=tweets['content'].apply(lambda x: clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "268d7499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>disc_cat</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587451436683264</td>\n",
       "      <td>bitch lmfaooooo gone rock sock ass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587450710958081</td>\n",
       "      <td>nvr vw person simpli cost repair hassl get don...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587450673319940</td>\n",
       "      <td>hate wen bitch say stop act care df said act l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587450547634179</td>\n",
       "      <td>dnc pay well ask brooklyn dad hes lucki get pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587449503264769</td>\n",
       "      <td>sinong bitch ba yung hindi marunong mag sorri ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187658489856</td>\n",
       "      <td>happi st david day everyon wale council blind ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187603959808</td>\n",
       "      <td>congrat sir pls sir want sir better nigeria pu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187595472896</td>\n",
       "      <td>ne abbiamo sempr bisogno</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187587100672</td>\n",
       "      <td>wait video channel bro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187578712064</td>\n",
       "      <td>nhn cartier vng chim ngng v khng th chi nhn ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310919 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date                   id  \\\n",
       "0       28 February 2023  1630587451436683264   \n",
       "1       28 February 2023  1630587450710958081   \n",
       "2       28 February 2023  1630587450673319940   \n",
       "3       28 February 2023  1630587450547634179   \n",
       "4       28 February 2023  1630587449503264769   \n",
       "...                  ...                  ...   \n",
       "99996      01 March 2023  1630854187658489856   \n",
       "99997      01 March 2023  1630854187603959808   \n",
       "99998      01 March 2023  1630854187595472896   \n",
       "99999      01 March 2023  1630854187587100672   \n",
       "100000     01 March 2023  1630854187578712064   \n",
       "\n",
       "                                                  content  likes  retweets  \\\n",
       "0                      bitch lmfaooooo gone rock sock ass      0         0   \n",
       "1       nvr vw person simpli cost repair hassl get don...      0         0   \n",
       "2       hate wen bitch say stop act care df said act l...      0         0   \n",
       "3       dnc pay well ask brooklyn dad hes lucki get pe...      0         0   \n",
       "4       sinong bitch ba yung hindi marunong mag sorri ...      0         0   \n",
       "...                                                   ...    ...       ...   \n",
       "99996   happi st david day everyon wale council blind ...      0         0   \n",
       "99997   congrat sir pls sir want sir better nigeria pu...      0         0   \n",
       "99998                            ne abbiamo sempr bisogno      0         0   \n",
       "99999                              wait video channel bro      0         0   \n",
       "100000  nhn cartier vng chim ngng v khng th chi nhn ca...      0         0   \n",
       "\n",
       "       disc_cat  Unnamed: 0.1  \n",
       "0        gender           NaN  \n",
       "1        gender           NaN  \n",
       "2        gender           NaN  \n",
       "3        gender           NaN  \n",
       "4        gender           NaN  \n",
       "...         ...           ...  \n",
       "99996   control           NaN  \n",
       "99997   control           NaN  \n",
       "99998   control           NaN  \n",
       "99999   control           NaN  \n",
       "100000  control           NaN  \n",
       "\n",
       "[310919 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc81d075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "control          100001\n",
       "sex               64127\n",
       "gender            54108\n",
       "mental_health     44088\n",
       "race              35569\n",
       "health            13026\n",
       "Name: disc_cat, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['disc_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71282a3",
   "metadata": {},
   "source": [
    "# Scaling discrimination categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b816a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to map each category to a numerical value\n",
    "discrimination_map = {\n",
    "    'control': 0,\n",
    "    'sex': 1,\n",
    "    'gender': 2,\n",
    "    'race': 3,\n",
    "    'mental_health': 4,\n",
    "    'health': 5\n",
    "}\n",
    "\n",
    "# Encoding the discrimination categories\n",
    "tweets['disc_cat_num']  = tweets['disc_cat'].apply(lambda x: discrimination_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b374553d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100001\n",
       "1     64127\n",
       "2     54108\n",
       "4     44088\n",
       "3     35569\n",
       "5     13026\n",
       "Name: disc_cat_num, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['disc_cat_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42814bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>disc_cat</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>disc_cat_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587451436683264</td>\n",
       "      <td>bitch lmfaooooo gone rock sock ass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587450710958081</td>\n",
       "      <td>nvr vw person simpli cost repair hassl get don...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587450673319940</td>\n",
       "      <td>hate wen bitch say stop act care df said act l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587450547634179</td>\n",
       "      <td>dnc pay well ask brooklyn dad hes lucki get pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28 February 2023</td>\n",
       "      <td>1630587449503264769</td>\n",
       "      <td>sinong bitch ba yung hindi marunong mag sorri ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187658489856</td>\n",
       "      <td>happi st david day everyon wale council blind ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187603959808</td>\n",
       "      <td>congrat sir pls sir want sir better nigeria pu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187595472896</td>\n",
       "      <td>ne abbiamo sempr bisogno</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187587100672</td>\n",
       "      <td>wait video channel bro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>01 March 2023</td>\n",
       "      <td>1630854187578712064</td>\n",
       "      <td>nhn cartier vng chim ngng v khng th chi nhn ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310919 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date                   id  \\\n",
       "0       28 February 2023  1630587451436683264   \n",
       "1       28 February 2023  1630587450710958081   \n",
       "2       28 February 2023  1630587450673319940   \n",
       "3       28 February 2023  1630587450547634179   \n",
       "4       28 February 2023  1630587449503264769   \n",
       "...                  ...                  ...   \n",
       "99996      01 March 2023  1630854187658489856   \n",
       "99997      01 March 2023  1630854187603959808   \n",
       "99998      01 March 2023  1630854187595472896   \n",
       "99999      01 March 2023  1630854187587100672   \n",
       "100000     01 March 2023  1630854187578712064   \n",
       "\n",
       "                                                  content  likes  retweets  \\\n",
       "0                      bitch lmfaooooo gone rock sock ass      0         0   \n",
       "1       nvr vw person simpli cost repair hassl get don...      0         0   \n",
       "2       hate wen bitch say stop act care df said act l...      0         0   \n",
       "3       dnc pay well ask brooklyn dad hes lucki get pe...      0         0   \n",
       "4       sinong bitch ba yung hindi marunong mag sorri ...      0         0   \n",
       "...                                                   ...    ...       ...   \n",
       "99996   happi st david day everyon wale council blind ...      0         0   \n",
       "99997   congrat sir pls sir want sir better nigeria pu...      0         0   \n",
       "99998                            ne abbiamo sempr bisogno      0         0   \n",
       "99999                              wait video channel bro      0         0   \n",
       "100000  nhn cartier vng chim ngng v khng th chi nhn ca...      0         0   \n",
       "\n",
       "       disc_cat  Unnamed: 0.1  disc_cat_num  \n",
       "0        gender           NaN             2  \n",
       "1        gender           NaN             2  \n",
       "2        gender           NaN             2  \n",
       "3        gender           NaN             2  \n",
       "4        gender           NaN             2  \n",
       "...         ...           ...           ...  \n",
       "99996   control           NaN             0  \n",
       "99997   control           NaN             0  \n",
       "99998   control           NaN             0  \n",
       "99999   control           NaN             0  \n",
       "100000  control           NaN             0  \n",
       "\n",
       "[310919 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0272c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ctrl_cleaned = tweets[tweets['disc_cat'] == 'control'].copy()\n",
    "tweets_disc_cleaned = tweets[tweets['disc_cat'] != 'control'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "223a266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ctrl_cleaned.to_csv('Data/tweets_ctrl_cleaned.csv', index=False)\n",
    "tweets_disc_cleaned.to_csv('Data/tweets_disc_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
